{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Decision Tree, and how does it work in the context of\n",
        "classification?\n",
        ">>Answer:\n",
        "A Decision Tree is a model that makes decisions step by step, just like asking yes/no questions.\n",
        "\n",
        "Each node checks a feature (like “Is petal length > 2.5?”).\n",
        "\n",
        "Each branch represents the answer (Yes or No).\n",
        "\n",
        "Each leaf gives the final class (like Iris-setosa or Iris-versicolor).\n",
        "\n",
        "It divides data into smaller groups based on the most useful features until it can clearly decide the class."
      ],
      "metadata": {
        "id": "_b58246aw-Is"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What is Gini Impurity and Entropy? How do they affect splits?\n",
        ">>Answer:\n",
        "Both Gini and Entropy tell how mixed the data is in a node.\n",
        "\n",
        "- Gini Impurity → Measures how often a random sample would be wrongly labeled.\n",
        "\n",
        "Formula: G=1−∑pi2​\n",
        "\n",
        "- Entropy → Measures the randomness in data.\n",
        "\n",
        "Formula: H=−∑pi​log2​pi​\n",
        "\n",
        "Effect:\n",
        "The tree looks for the feature that gives the lowest impurity (or highest purity) after splitting.\n",
        "\n",
        "- Gini is faster.\n",
        "\n",
        "- Entropy is based on information theory.\n",
        "Both usually give similar results."
      ],
      "metadata": {
        "id": "zirE-I06xwl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: Difference between Pre-Pruning and Post-Pruning\n",
        "\n",
        ">>Answer:\n",
        "\n",
        "- Pre-Pruning: Stop the tree early (like setting max_depth=3).\n",
        "\n",
        "Advantage: Saves time and avoids overfitting early.\n",
        "\n",
        "- Post-Pruning: First grow a full tree, then remove unnecessary branches.\n",
        "\n",
        "Advantage: Gives better accuracy because it removes only weak parts after checking performance."
      ],
      "metadata": {
        "id": "ODdRVuk1y5rJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is Information Gain, and why is it important?\n",
        "\n",
        ">>Answer:\n",
        "Information Gain tells how much “impurity” is reduced after a split.\n",
        "\n",
        "Information Gain= Impurity before​−Impurity after​\n",
        "\n",
        "The higher the gain, the better the split.\n",
        "It helps the Decision Tree choose the best feature and condition for each node."
      ],
      "metadata": {
        "id": "2P_rklYwzB08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Real-world applications, advantages, and limitations\n",
        "\n",
        ">>Answer:\n",
        "- Applications:\n",
        "\n",
        "Predicting diseases (healthcare)\n",
        "\n",
        "Loan approval (banking)\n",
        "\n",
        "Detecting fraud (finance)\n",
        "\n",
        "Customer churn prediction (marketing)\n",
        "\n",
        "- Advantages:\n",
        "\n",
        "Easy to understand and visualize\n",
        "\n",
        "Works with both numbers and categories\n",
        "\n",
        "Needs little data preparation\n",
        "\n",
        "- Limitations:\n",
        "\n",
        "Can overfit if not pruned\n",
        "\n",
        "Small changes in data can change the tree\n",
        "\n",
        "Not great with continuous smooth decisions alone (better in ensembles)"
      ],
      "metadata": {
        "id": "zL0BLPAkzie4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program to:\n",
        "\n",
        "-  Load the Iris Dataset\n",
        "\n",
        "- Train a Decision Tree Classifier using the Gini criterion\n",
        "\n",
        "-  Print the model’s accuracy and feature importances\n"
      ],
      "metadata": {
        "id": "Bn1TXdpbztVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree using Gini criterion\n",
        "model = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "print(\"Feature Importances:\")\n",
        "for name, importance in zip(iris.feature_names, model.feature_importances_):\n",
        "    print(f\"{name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp5-o17tErkA",
        "outputId": "ff1a7cc7-7d38-4d30-a5f5-3c98bcddcc68"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0\n",
            "Feature Importances:\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0167\n",
            "petal length (cm): 0.9061\n",
            "petal width (cm): 0.0772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to:\n",
        "\n",
        "- Load the Iris Dataset\n",
        "- Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "a fully-grown tree.\n"
      ],
      "metadata": {
        "id": "aT2ZFsB2E4kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Decision Tree with max_depth = 3\n",
        "tree_limited = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "tree_limited.fit(X_train, y_train)\n",
        "y_pred_limited = tree_limited.predict(X_test)\n",
        "acc_limited = accuracy_score(y_test, y_pred_limited)\n",
        "\n",
        "# Fully-grown Decision Tree\n",
        "tree_full = DecisionTreeClassifier(random_state=42)\n",
        "tree_full.fit(X_train, y_train)\n",
        "y_pred_full = tree_full.predict(X_test)\n",
        "acc_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "# Print comparison\n",
        "print(\"Accuracy (max_depth=3):\", acc_limited)\n",
        "print(\"Accuracy (fully-grown tree):\", acc_full)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKpz5wRJFEFL",
        "outputId": "2d38346a-137b-4db5-e483-6257aa0fe688"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (max_depth=3): 1.0\n",
            "Accuracy (fully-grown tree): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "- Load the California Housing dataset from sklearn\n",
        "- Train a Decision Tree Regressor\n",
        "- Print the Mean Squared Error (MSE) and feature importances\n"
      ],
      "metadata": {
        "id": "gdwuP2cYHz5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load data\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Regressor\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and find error\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Feature Importances:\")\n",
        "for name, val in zip(data.feature_names, model.feature_importances_):\n",
        "    print(f\"{name}: {val:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHmnNfEoH4kg",
        "outputId": "b16a0efa-4e94-4c67-eafe-350ba269770f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.495235205629094\n",
            "Feature Importances:\n",
            "MedInc: 0.5285\n",
            "HouseAge: 0.0519\n",
            "AveRooms: 0.0530\n",
            "AveBedrms: 0.0287\n",
            "Population: 0.0305\n",
            "AveOccup: 0.1308\n",
            "Latitude: 0.0937\n",
            "Longitude: 0.0829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:\n",
        "- Load the Iris Dataset\n",
        "- Tune the Decision Tree’s max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "- Print the best parameters and the resulting model accuracy"
      ],
      "metadata": {
        "id": "QlH4YPdVILQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set parameters to test\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5],\n",
        "    'min_samples_split': [2, 3, 4, 5]\n",
        "}\n",
        "\n",
        "# Use GridSearchCV to find best parameters\n",
        "grid = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and accuracy\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCoGdWDHIPi1",
        "outputId": "c82055f4-a1eb-4925-98c5-222c41a3a7e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 2}\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you’re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "- Handle the missing values\n",
        "- Encode the categorical features\n",
        "- Train a Decision Tree model\n",
        "- Tune its hyperparameters\n",
        "- Evaluate its performance\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting.\n",
        "\n",
        ">>Answer:\n",
        "If we have patient data and want to predict disease:\n",
        "\n",
        "- Handle missing values:\n",
        "\n",
        "Replace with average (for numbers) or most frequent value (for text).\n",
        "\n",
        "- Encode categorical data:\n",
        "\n",
        "Convert text values (like “Male”, “Female”) into numbers using Label Encoding or One-Hot Encoding.\n",
        "\n",
        "- Train the Decision Tree:\n",
        "\n",
        "Split data → 80% training, 20% testing.\n",
        "\n",
        "Use DecisionTreeClassifier from sklearn.\n",
        "\n",
        "- Tune hyperparameters:\n",
        "\n",
        "Try different max_depth, min_samples_split using GridSearchCV to get the best model.\n",
        "\n",
        "- Evaluate performance:\n",
        "\n",
        "Check accuracy, precision, recall, or confusion matrix on the test set.\n",
        "\n",
        "Business Value:\n",
        "This model helps doctors and hospitals predict diseases early, make faster decisions, and reduce diagnosis time — improving patient care and saving costs."
      ],
      "metadata": {
        "id": "i1eZ1QOcIZ-z"
      }
    }
  ]
}